# Comparative Analysis of different GANs and VAEs

In this paper, the comparative analysis of generative adversarial networks (GANs) and variational autoencoders (VAEs) is presented for image generation based on the MNIST Dataset of Handwritten Digits.

## Table of Contents

- [Introduction](#introduction)
- [Dataset Used](#dataset)
- [Comparative Analysis Criterias](#analysis)

## Introduction

Generative models are a subset of deep learning models that can uncover the underlying structure of the dataset in question and produce new samples using that structure. Two well-known generative models, generative adversarial networks (GANs) and variational autoencoders (VAEs), have demonstrated outstanding performance in image-generating challenges.

## Dataset Used

The MNIST dataset of handwritten digits is a frequently used benchmark dataset in the fields of computer vision and machine learning. It is made up of 70,000 28x28 pixel grayscale pictures of handwritten numbers from 0 to 9.

## Comparative Analysis Criterias

### Architecture
### Image Generation Quality
### Training Stability
### Latent Space

